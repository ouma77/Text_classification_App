# -*- coding: utf-8 -*-
"""model_ML_Script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1haAo3hkj9Xbn59VyaHvI2kPXsIw4i915

###**Importer les bibliothèque nécessaire**
"""

import numpy as np
import pandas as pd
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.stem.snowball import FrenchStemmer
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.naive_bayes import MultinomialNB
from sklearn import tree
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.externals import joblib
import pickle
nltk.download('punkt')

"""###**Importer le fichier excel et stocker notre input (la designation) et les deux output à prédire (categorie et sous categorie) dans un seul tableau**"""

All_excel = pd.read_excel (r'CSS.xlsx')
Usefull_data = pd.DataFrame(All_excel, columns= ['Designation','Catégorie', 'Sous catégorie'])
Clean_data = Usefull_data.dropna()
Clean_data

Clean_data['Catégorie'].value_counts()

Clean_data['Sous catégorie'].value_counts()

"""#**Preprocessing**

###**Tokenization et Nettoyage des données**
"""

def preprocess(corp):
  stemmer = FrenchStemmer()
  word_tokens = [word.lower() for word in word_tokenize(corp)]
  words = [stemmer.stem(word.lower()) for word in word_tokens if word.isalpha() and len(word)>1] 
  return ' '.join(words)

Clean_data.Designation.apply(preprocess)
Clean_data['Des'] = Clean_data.Designation.apply(preprocess)
Clean_data['Des']

"""##**Affecter des integer to classes (Sous Categories)**"""

def labeling(element):
    if element == 'MPR':
        return 0
    elif element == 'BAT':
        return 1
    elif element == 'INFO':
        return 2
    elif element == 'MOB':
        return 3
        
Clean_data['SousCat'] = Clean_data['Sous catégorie'].apply(labeling)
Clean_data

"""###**Après la phase du prétraitement, On obtient un contenu nettoyé et prêt pour la représentation vectorielle.**

###**TF IDF (pour la vectorisation)**
"""

# Target Selection
Target = Clean_data.SousCat

# Apply vectorizer
tfidf = TfidfVectorizer()
tfi0 = tfidf.fit(Clean_data.Des)
tfi = tfidf.transform(Clean_data.Des)
#tfi = tfidf.fit_transform(Clean_data.Des)
sparce_matrice = tfi.toarray()

#split
X_sample_train, X_sample_test, y_sample_train, y_sample_test = train_test_split(
    tfi, Target,
    test_size=0.2,
    random_state=44
)

"""###**Accuracy Tests on multiple models to choose the best !!! ( NB classifier, Knn, SVM, Decision tree)**
- if prediction = 0 => la classe MPR
- if prediction = 1 => la classe BAT
- if prediction = 2 => la classe INFO
- if prediction = 3 => la classe MOB

"""

y_sample_test

# fit the training dataset on the NB classifier
parameters = {'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)}
Naive = MultinomialNB(alpha=0.1)
grid_search= GridSearchCV(Naive, parameters)
grid_search.fit(X_sample_train,y_sample_train)

# predict the labels on validation dataset
prediction0 = grid_search.predict(X_sample_test)
print(grid_search.best_estimator_)
print("Les designation appartiennent à la sous categorie : ", prediction0)

print(classification_report(y_sample_test, prediction0))

knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_sample_train, y_sample_train)
prediction= knn.predict(X_sample_test)
print("Les designation appartiennent à la sous categorie : ", prediction)

print(classification_report(y_sample_test, prediction))

X_sample_train.shape

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
sc = StandardScaler(with_mean=False)
sc.fit(X_sample_train)
X_train_std = sc.transform(X_sample_train)
X_test_std = sc.transform(X_sample_test)

# Instantiate the Support Vector Classifier (SVC)
svc = SVC(C=1.0, random_state=1, kernel='linear')

# Fit the model
svc.fit(X_train_std, y_sample_train)

# Make the predictions
y_predict = svc.predict(X_test_std)

print("Les designation appartiennent à la sous categorie : ", y_predict)

print(X_train_std[1])

print(classification_report(y_sample_test, y_predict))

clf = tree.DecisionTreeClassifier(criterion='gini', max_depth=None,min_impurity_split=1e-07, min_samples_leaf=1,
 min_samples_split=2)
DecisionTree = clf.fit(X_sample_train, y_sample_train)
y_predict2 = DecisionTree.predict(X_sample_test)
print("Les designation appartiennent à la sous categorie : ", y_predict2)

print(classification_report(y_sample_test, y_predict2))

"""##**Serialization to export the model : using Joblib**


"""

# Save to file in the current working directory
joblib_file = "joblib_model.pkl"
joblib.dump(DecisionTree, joblib_file)

md = joblib.load('joblib_model.pkl')

import pickle

vect = pickle.load(open('tfidf.pickle', 'rb'))
new_sentence = [input()]
new = vect.transform(new_sentence)
print(new_sentence)
print(new)
md.predict(new)

if (md.predict(new)==0):
  print("MPR")
if (md.predict(new)==1):
  print("BAT")
if (md.predict(new)==2):
  print("INFO")
if (md.predict(new)==3):
  print("MOB")

vect = pickle.load(open('tfidf.pickle', 'rb'))
DataInAList = []
new = []
df = pd.read_excel ('CSS.xlsx')
corpus = df['Designation'].values

for sent in corpus:

  new = vect.transform([str(sent)])
  prediction = md.predict(new)
  res_prediction = '?'
  if (prediction == 0):
    res_prediction = "MPR"
  if (prediction == 1):
    res_prediction = "BAT"
  if (prediction == 2):
    res_prediction = "INFO"
  if (prediction == 3):
    res_prediction = "MOB"

  DataInAList.append(res_prediction)
df["Prediction sous cat"] = DataInAList

df.to_excel("NewExcel.xlsx",index=False)
